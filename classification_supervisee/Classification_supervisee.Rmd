---
title: "Classification_supervisée"
output: html_notebook
---

```{r}
sub_sante_mentale=read.csv("sante_mentale_regrouped.csv")
sub_sante_mentale <- sub_sante_mentale[sub_sante_mentale$depressif %in% c("Oui", "Non"), ]

# Convertir toutes les variables du dataframe en facteurs
for (column in names(sub_sante_mentale)) {
  sub_sante_mentale[[column]] <- as.factor(sub_sante_mentale[[column]])
}

# Subsetting the dataframe to keep only rows where depressif is "Oui" or "Non"
sub_sante_mentale

# Assuming your data frame is named 'data'
sub_sante_mentale <- sub_sante_mentale[c("ville_foyer", "mange_a_ta_faim", "alcool", "Conflits.Familiaux", 
                        "tiers_temps", "niveau_etude", "anxiété", "suivi_psycho", 
                        "diagnostic_episode_depressif", "depressif", "suivi_medicale_depressif")]

sub_sante_mentale
```


```{r}
# Préparation des données
set.seed(1) # Permet de pouvoir reproduire les mêmes résultats
n <- nrow(sub_sante_mentale) 
test.ratio <- 0.2 # Le taux de la db qu'on va utilisé comme test
n.test <- round(n * test.ratio) # Permet de savoir le nombre d'observation pour les test
tr <- sample(1:n, n.test)  
sub_sante_mentale.test <- sub_sante_mentale[tr, ] 
sub_sante_mentale.train <- sub_sante_mentale[-tr, ]

```

```{r}

# Examiner les valeurs uniques par groupe de 'depressif'
aggregate(sub_sante_mentale[], by=list(sub_sante_mentale$depressif), function(x) length(unique(x)))


```

```{r}
library(FactoMineR)
library(factoextra)
library(klaR)
library(MASS)
library(rpart)
library(rpart.plot)
library(pROC)
```


# LDA
```{r}

# Assuming all data issues are fixed
res_lda <- lda(depressif ~ ., data = sub_sante_mentale.train)
pred_lda <- predict(res_lda, newdata = sub_sante_mentale.test)$class
table_lda <- table(Predicted = pred_lda, Actual = sub_sante_mentale.test$depressif)
accuracy_lda <- sum(diag(table_lda)) / n.test
print(accuracy_lda)

```


LDA
```{r}
library(MASS)
# LDA
res_lda <- lda(sub_sante_mentale$depressif ~ ., data =sub_sante_mentale)
summary(res_lda)
```

Prédiction
```{r}
pred_lda_classe = predict(res_lda, newdata=sub_sante_mentale.test)$class
print(pred_lda_classe)
```


Accuracy
```{r}
confusion_table_lda <- table(Prédiction = pred_lda_classe, Réalité = sub_sante_mentale.test$depressif)
print(confusion_table_lda)

print(sum(diag(confusion_table_lda))/n.test)

#accuracy_lda = mean(pred_lda_classe == sub_sante_mentale.test$DIFF)
#print(accuracy_lda)

```



Proba
```{r}
#proba a posteriori de succes (dans la deuxième colonne) : 
pred_lda <- predict(res_lda,newdata=sub_sante_mentale.test)$posterior[,2] 

ROC_lda <- roc(sub_sante_mentale.test$depressif, pred_lda)
plot(ROC_lda, print.auc=TRUE,  print.auc.y = 0.5)
ROC_lda$auc
```



```{r}
# Courbe ROC pour LDA
library(pROC)
pred_lda_prob <- predict(res_lda, newdata=sub_sante_mentale.test)$posterior[,2]
ROC_lda <- roc(sub_sante_mentale.test$depressif, pred_lda_prob)
plot(ROC_lda, print.auc=TRUE)
```


# CART

```{r}
library(rpart)
arbre.opt <- rpart(depressif~., data=sub_sante_mentale.train)
pred_cart <- predict(arbre.opt, sub_sante_mentale.test, type="class")
table_cart <- table(Predicted=pred_cart, Actual=sub_sante_mentale.test$depressif)
accuracy_cart <- sum(diag(table_cart)) / n.test

# Courbe ROC pour CART
pred_cart_prob <- predict(arbre.opt, sub_sante_mentale.test, type="prob")[,2]
ROC_cart <- roc(sub_sante_mentale.test$depressif, pred_cart_prob)
plot(ROC_cart, print.auc=TRUE)

confusion_table_cart <- table(Prédiction = pred_cart, Réalité = sub_sante_mentale.test$depressif)
print(confusion_table_cart)
print(accuracy_cart)


```



# Random Forest

```{r}
library(randomForest)
fit_RF <- randomForest(depressif~., data=sub_sante_mentale.train)
pred_RF <- predict(fit_RF, sub_sante_mentale.test, type="class")
table_RF <- table(Predicted=pred_RF, Actual=sub_sante_mentale.test$depressif)
accuracy_RF <- sum(diag(table_RF)) / n.test

# Courbe ROC pour Random Forest
pred_RF_prob <- predict(fit_RF, sub_sante_mentale.test, type="prob")[,2]
ROC_RF <- roc(sub_sante_mentale.test$depressif, pred_RF_prob)
plot(ROC_RF, print.auc=TRUE)

confusion_table_RF <- table(Prédiction = pred_RF, Réalité = sub_sante_mentale.test$depressif)
print(confusion_table_RF)
print(accuracy_RF)

```
# AdaBoost --------------------------------------------------------------------------
```{r}

library(gbm)
library(ROCR)  # To perform ROC analysis

# Convert 'depressif' to a binary numeric variable where "Non" is 0 and "Oui" is 1
# Ensure that this transformation covers all data
sub_sante_mentale$depressif_numeric <- ifelse(sub_sante_mentale$depressif == "Oui", 1, 0)

# Split the data into training and test sets
set.seed(1)  # For reproducibility
n <- nrow(sub_sante_mentale)
test_ratio <- 0.2
n.test <- round(n * test_ratio)
tr <- sample(1:n, n.test)

sub_sante_mentale.test <- sub_sante_mentale[tr, ]
sub_sante_mentale.train <- sub_sante_mentale[-tr, ]

# Train the AdaBoost model using the gbm package
fit.adaboost <- gbm(depressif_numeric ~ ., data = sub_sante_mentale.train, 
                    distribution = "adaboost", n.trees = 3000, 
                    cv.folds = 5, shrinkage = 0.01, interaction.depth = 1)

# Determine the optimal number of trees using cross-validation
B.opt = gbm.perf(fit.adaboost, method="cv")

# Predict on the test dataset using the optimal number of trees
pred_adaboost <- predict(fit.adaboost, newdata = sub_sante_mentale.test, 
                         type = "response", n.trees = B.opt)

# Round predictions to obtain binary outcomes
predicted <- ifelse(pred_adaboost > 0.5, 1, 0)

# Create a confusion matrix and calculate accuracy
confusion_adaboost <- table(Predicted = predicted, Actual = sub_sante_mentale.test$depressif_numeric)
accuracy_adaboost <- sum(diag(confusion_adaboost)) / nrow(sub_sante_mentale.test)

# Calculate the AUC
pred_obj <- prediction(pred_adaboost, sub_sante_mentale.test$depressif_numeric)
perf_obj <- performance(pred_obj, "auc")
auc_adaboost <- perf_obj@y.values[[1]]

# Display the results
print(confusion_adaboost)
print(paste("Accuracy:", accuracy_adaboost))
print(paste("AUC:", auc_adaboost))


```


# Regression logistique --------------------------------------------------------------

```{r}
# Assurez-vous que 'depressif' est un facteur (si ce n'est pas déjà le cas)
sub_sante_mentale.train$depressif <- as.factor(sub_sante_mentale.train$depressif)
sub_sante_mentale.test$depressif <- as.factor(sub_sante_mentale.test$depressif)

# Créer des matrices pour glmnet sans inclure la colonne 'depressif'
x_train <- model.matrix(~ . - 1 - depressif, data = sub_sante_mentale.train)  # '-1' pour exclure l'intercept et '-depressif' pour exclure la colonne cible
y_train <- sub_sante_mentale.train$depressif  # Utiliser 'depressif' comme la variable cible

x_test <- model.matrix(~ . - 1 - depressif, data = sub_sante_mentale.test)
y_test <- sub_sante_mentale.test$depressif

# Assurer que 'depressif' dans y_train et y_test est bien un facteur numérique pour glmnet
y_train <- as.numeric(y_train) - 1  # Convertir en 0 et 1 pour glmnet
y_test <- as.numeric(y_test) - 1

library(glmnet)
library(pROC)

# Suppose that x_train and y_train are already defined and are numeric matrices/vectors

# Fit a logistic regression model with Lasso regularization
lasso_model <- glmnet(x_train, y_train, family = 'binomial', alpha = 1)

# Cross-validation to find the optimal lambda
cv_lasso <- cv.glmnet(x_train, y_train, family = "binomial")

# Plot to visually check the lambda values
plot(cv_lasso)

# Extract the lambda that minimizes the cross-validation error
best_lambda <- cv_lasso$lambda.min
print(paste("Best lambda: ", best_lambda))

# Make sure best_lambda is numeric
if (!is.numeric(best_lambda)) {
    stop("best_lambda should be numeric.")
}

# Prediction using Lasso model
pred_lasso <- predict(lasso_model, newx = x_test, s = best_lambda, type = "response")

# Convert probabilities to binary outcomes
predicted_classes <- ifelse(pred_lasso > 0.5, 1, 0)

# Evaluate model
confusion_matrix <- table(Predicted = predicted_classes, Actual = y_test)
accuracy_RL <- sum(diag(confusion_matrix)) / length(y_test)
print(confusion_matrix)
print(paste("Accuracy:", accuracy))

# ROC Curve and AUC calculation
ROC_RL <- roc(y_test, pred_lasso[,1])  # make sure to use the correct index if pred_lasso is a matrix
plot(ROC_RL, print.auc = TRUE)
auc_value <- auc(ROC_RL)
print(paste("AUC:", auc_value))

```

# Comparaison des modèles
```{r}
results <- rbind(
  lda=c(Accuracy=accuracy_lda, AUC=as.numeric(ROC_lda$auc)),
  cart=c(Accuracy=accuracy_cart, AUC=as.numeric(ROC_cart$auc)),
  rf=c(Accuracy=accuracy_RF, AUC=as.numeric(ROC_RF$auc)),
  adaboost=c(c(Accuracy=accuracy_RL, AUC=as.numeric(ROC_RL$auc))),
  rl=c(c(Accuracy=accuracy_adaboost, AUC=auc_adaboost))
)
results

# Afficher les résultats et identifier le meilleur modèle
best_model <- apply(results, 2, which.max)
best_model
```

