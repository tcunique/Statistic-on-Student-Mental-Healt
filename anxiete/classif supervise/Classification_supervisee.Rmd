---
title: "Classification_supervisée"
output:
  pdf_document: default
  html_notebook: default
---


Tout d'abord, on filtre les lignes du dataframe pour ne conserver que celles où la variable depressif prend les valeurs "Oui" ou "Non". Ensuite, on convertit toutes les variables du dataframe en facteurs, ce qui permet de traiter chaque colonne comme une variable catégorielle. Enfin on conserve que les colonnes spécifiées : ville_foyer, mange_a_ta_faim, alcool, Conflits.Familiaux, tiers_temps, niveau_etude, anxiété, suivi_psycho, diagnostic_episode_depressif, depressif et suivi_medicale_depressif. 
Ces variables ont été sélectionné après l'analyse du chisq2.
```{r}
sub_sante_mentale=read.csv("sante_mentale_regrouped.csv")
sub_sante_mentale <- sub_sante_mentale[sub_sante_mentale$anxiété %in% c("Oui", "Non"), ]

# Convertir toutes les variables du dataframe en facteurs
for (column in names(sub_sante_mentale)) {
  sub_sante_mentale[[column]] <- as.factor(sub_sante_mentale[[column]])
}

# Subsetting the dataframe to keep only rows where depressif is "Oui" or "Non"
#sub_sante_mentale
# Assuming your data frame is named 'data'
sub_sante_mentale <- sub_sante_mentale[c("passion", "parents_divorcés","Conflits.Familiaux","difficultées_scolaires","anxiété", "depressif")]

#sub_sante_mentale
attach(sub_sante_mentale)
```



Ce code permet de diviser le jeu de données initial en deux parties : une pour l'entraînement du modèle (sub_sante_mentale.train) et une pour son évaluation (sub_sante_mentale.test).
```{r}
# Préparation des données
set.seed(1) # Permet de pouvoir reproduire les mêmes résultats
n <- nrow(sub_sante_mentale) 
test.ratio <- 0.2 # Le taux de la db qu'on va utilisé comme test
n.test <- round(n * test.ratio) # Permet de savoir le nombre d'observation pour les test
tr <- sample(1:n, n.test)  
sub_sante_mentale.test <- sub_sante_mentale[tr, ] 
sub_sante_mentale.train <- sub_sante_mentale[-tr, ]
```



```{r}
# Examiner les valeurs uniques par groupe de 'depressif'
aggregate(sub_sante_mentale[], by=list(sub_sante_mentale$anxiété), function(x) length(unique(x)))
```

```{r}
library(FactoMineR)
library(factoextra)
library(klaR)
library(MASS)
library(rpart)
library(rpart.plot)
library(pROC)
```


# LDA
```{r}
# Assuming all data issues are fixed
res_lda <- lda(anxiété ~ ., data = sub_sante_mentale.train)
```


ROC lda
```{r}
#proba a posteriori de succes (dans la deuxième colonne) : 
pred_lda <- predict(res_lda,newdata=sub_sante_mentale.test)

ROC_lda <- roc(sub_sante_mentale.test$anxiété, pred_lda$posterior[,2] )
plot(ROC_lda, print.auc=TRUE,  print.auc.y = 0.5)
ROC_lda$auc
```


Accuracy Lda
```{r}
confusion_table_lda = table(Prédiction = pred_lda$class, Réalité = sub_sante_mentale.test$anxiété)
confusion_table_lda

accuracy_lda = mean(pred_lda$class == sub_sante_mentale.test$anxiété)
accuracy_lda
```


# CART

```{r}
library(rpart)
arbre.opt <- rpart(anxiété~., data=sub_sante_mentale.train)
rpart.plot(arbre.opt, type=4, digits=3, roundint=FALSE)
```


ROC Cart
```{r}
# Courbe ROC pour CART
pred_cart <- predict(arbre.opt, sub_sante_mentale.test, type="prob")[,2]
ROC_cart <- roc(sub_sante_mentale.test$anxiété, pred_cart)
plot(ROC_cart, print.auc=TRUE)
```


Accuracy Cart
```{r}
pred_cart_class = predict(arbre.opt, sub_sante_mentale.test, type="class")
confusion_table_cart = table(Prédiction = pred_cart_class, Réalité = sub_sante_mentale.test$anxiété)
confusion_table_cart

accuracy_cart = mean(pred_cart_class == sub_sante_mentale.test$anxiété)
accuracy_cart
```

# Random Forest

```{r}
library(randomForest)
fit_RF <- randomForest(anxiété~., data=sub_sante_mentale.train)
fit_RF
plot(fit_RF)
```
C'est très écarté, nous allons donc les rassembler en utilisant la méthode suivante :

Ce code utilise SMOTE pour équilibrer les classes dans le jeu de données d'entraînement, et affiche la nouvelle répartition des classes pour vérifier l'efficacité de l'équilibrage

SMOTE (Synthetic Minority Over-sampling Technique) est une méthode utilisée pour traiter le déséquilibre des classes dans les jeux de données. Le déséquilibre des classes se produit lorsqu'une classe (la classe minoritaire) est sous-représentée par rapport aux autres classes (la classe majoritaire). Ce déséquilibre peut entraîner des modèles biaisés qui performent mal sur la classe minoritaire.
```{r}
library(DMwR)
data.train.balanced <- SMOTE(anxiété~., sub_sante_mentale.train)
table(data.train.balanced$anxiété)
#data.train.balanced
```

Recalculons le tout avec la nouvelle base de donnée équilibrée par la méthode SMOTE
```{r}
fit_RF <- randomForest(anxiété~.,data.train.balanced)
fit_RF
plot(fit_RF)
```

Nous remarquons que c'est un peu mieux et que cela se rapproche plus.

ROC RandomForest
```{r}
## aire sous courbe ROC
pred_RF = predict(fit_RF, sub_sante_mentale.test, type="prob")[,2] 
ROC_RF <- roc(sub_sante_mentale.test$anxiété, pred_RF)
ROC_RF$auc
plot(ROC_RF, print.auc=TRUE,  print.auc.y = 0.5)
```

Nous remarquons que nous obtenons une meilleure accuracy et une meilleur AUC avec la méthode random forest que par rapport aux deux autres. (LDA, CART)
Accuracy RandomForest
```{r}
pred_RF_class = predict(fit_RF, sub_sante_mentale.test, type="class")
confusion_table_rf = table(Prédiction = pred_RF_class, Réalité = sub_sante_mentale.test$anxiété)
confusion_table_rf

accuracy_rf = mean(pred_RF_class == sub_sante_mentale.test$anxiété)
accuracy_rf
```


# AdaBoost --------------------------------------------------------------------------
```{r}
library(gbm)
library(ROCR)  # To perform ROC analysis
```


Ici nous appliquons donc adaboost à la base de donnée. Nous faisons exprès de mettre en valeur numérique pour adaboost
```{r}
fit.adaboost=gbm(as.numeric(anxiété)-1 ~., sub_sante_mentale.train, distribution = "adaboost")
# au lieu de réouvrir le jeu de données, on utilise depressif en tant que variable qualitative, mais on la transforme en variable quantitative prenant les valeurs 0 et 1.
# vous pouvez vérifier ce que fait :
  #  as.numeric(data.train$DIFF)
  #  as.numeric(data.train$DIFF) -1
fit.adaboost
```





Les commandes fournies ajustent un modèle de Gradient Boosting Machine (GBM) en utilisant l'algorithme AdaBoost sur le jeu de données sub_sante_mentale.train, avec la variable cible depressif convertie en format numérique. On ajuste donc le modèle en utilisant la validation croisée à 5 plis pour évaluer la performance sur différents nombres d'arbres (jusqu'à 3000) tout en appliquant un taux d'apprentissage (shrinkage) de 0,01. L'objectif de ce processus est d'optimiser le nombre d'arbres (B.opt) pour l'algorithme AdaBoost en identifiant le point où l'erreur de validation croisée est minimisée. 
```{r}
### Calibrer B=n.tree par cross-validation : 
fit.adaboost=gbm(as.numeric(anxiété)-1 ~., sub_sante_mentale.train, distribution = "adaboost",cv.folds = 5, shrinkage = 0.01, n.trees=3000)
gbm.perf(fit.adaboost)
B.opt = gbm.perf(fit.adaboost, method="cv")
```
La courbe montre que le modèle GBM atteint la meilleure performance sur l'ensemble de validation à environ 100 itérations. Au-delà de ce point, ajouter plus d'arbres conduit à un surapprentissage, comme l'indique l'augmentation de l'erreur de validation croisée.

Réappliquons alors l'adaboost en prenant en compte le nombre d'arbre B.opt 
```{r}
## prédiction : 
pred_adaboost = predict(fit.adaboost, newdata=sub_sante_mentale.test, type = "response", n.trees = B.opt)

# Pour le transformer en class : 
class_adaboost = 1 * (pred_adaboost > 1/2)
```

Accuracy Adaboost
```{r}
confusion_table_adaboost = table(Prédiction = class_adaboost, Réalité = sub_sante_mentale.test$anxiété)
confusion_table_adaboost

accuracy_adaboost = mean(class_adaboost == sub_sante_mentale.test$anxiété)
accuracy_adaboost
```


ROC Adaboost
```{r}
## aire sous courbe ROC
ROC_adaboost <- roc(sub_sante_mentale.test$anxiété, pred_adaboost)
ROC_adaboost$auc
plot(ROC_adaboost, print.auc=TRUE,  print.auc.y = 0.5)
```
La courbe ROC montre que le modèle a une performance acceptable, avec une AUC de 0.779. Cela indique que le modèle est raisonnablement bon pour distinguer entre les classes positives et négatives, performe significativement mieux que le hasard mais n'atteint pas encore la catégorie de performance "bonne".



# Comparaison des modèles
```{r}
# Comparaison --------------------------------------------------------------
result=matrix(NA, ncol=4, nrow=2)
rownames(result)=c('accuracy', 'AUC')
colnames(result)=c('lda', 'cart', 'RF', "adaboost")
result[1,]= c(accuracy_lda, accuracy_cart, accuracy_rf,accuracy_adaboost)
result[2,]=c(ROC_lda$auc, ROC_cart$auc, ROC_RF$auc,  ROC_adaboost$auc)
result
apply(result,1, which.max )

plot(ROC_lda, xlim=c(1,0))
plot(ROC_cart, add=TRUE, col=2)
plot(ROC_RF, add=TRUE, col=3)
plot(ROC_adaboost, add=TRUE, col=4)
legend('bottom', col=1:4, paste(c('lda', 'cart', 'RF', "ada")),  lwd=1)
```
Parmi les modèles comparés, le modèle de Random Forest (courbe verte) démontre la meilleure performance en termes de sensibilité et de spécificité, suivi par l'AdaBoost (courbe bleue) et l'analyse discriminante linéaire (LDA, courbe noire). La performance du modèle CART n'est pas clairement visible, mais elle est vraisemblablement moins efficace selon les courbes présentées. Cette analyse suggère que le modèle de Random Forest est le classificateur le plus efficace pour ce jeu de données afin de déterminer si quelqu'un est possiblement dépressif ou non .
